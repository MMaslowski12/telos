"""
openai_agent.py

One‚Äëfile demo of a chat loop that lets GPT‚Äë4(o)/GPT‚Äë4.1 (or any OpenAI‚Äëcompatible model)
call the aerodynamic design tools defined in tools.py via JSON function calling.
Swap base_url and model id to run on Anthropic, DeepSeek, Together, etc.
"""

from typing import Any, Dict, Union, Optional, List, Tuple
import json
import inspect
import os

from pydantic import create_model
from openai import OpenAI

from tools import ToolManager

# ---------- Build JSON‚ÄëSchema tool list dynamically ----------
TOOLS: list[Dict[str, Any]] = []
CALLBACKS: Dict[str, Any] = {}

def _build_schema(fn):
    sig = inspect.signature(fn)
    fields = {}
    for name, param in sig.parameters.items():
        if name == "self":
            continue
        annotation = param.annotation if param.annotation is not inspect._empty else Any
        default = param.default if param.default is not inspect._empty else ...
        
        # Handle Optional types
        if getattr(annotation, "__origin__", None) is Union and type(None) in annotation.__args__:
            # Get the non-None type from Optional
            non_none_type = next(t for t in annotation.__args__ if t is not type(None))
            fields[name] = (non_none_type, default)
        else:
            fields[name] = (annotation, default)
            
    Model = create_model(f"{fn.__name__}Schema", **fields)
    Model.model_rebuild()  # Ensure the model is fully defined
    
    schema = Model.model_json_schema()
    return {
        "type": "function",
        "function": {
            "name": fn.__name__,
            "description": fn.__doc__ or f"{fn.__name__} autogenerated tool",
            "parameters": schema
        }
    }

def setup_tools(tm: ToolManager):
    """Initialize tools and callbacks for the given ToolManager instance."""
    global TOOLS, CALLBACKS
    TOOLS = []
    CALLBACKS = {}
    
    for name, fn in inspect.getmembers(tm, predicate=inspect.ismethod):
        if name.startswith("_"):
            continue
        schema = _build_schema(fn)
        TOOLS.append(schema)
        CALLBACKS[name] = fn

# ---------- OpenAI client ----------
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"), base_url="https://api.deepseek.com")

SYSTEM_MSG = {
    "role": "system",
    "content": (
        "You are AeroGPT, an expert aerodynamicist with direct access to XFLR5 via the provided tools. "
        "Think step‚Äëby‚Äëstep, decide whether a tool is needed, then call it. "
        "If no tool fits, simply respond as text."
        "Do not create your own airplane. The name of the airplane already created will be given to you by the user."
        "Check the specific names of the surfaces and sections of the airplane. Never do anything where unsure of the name of the surface or section."
    )
}

def chat_loop(tm: ToolManager):
    """Run the chat loop with the given ToolManager instance."""
    setup_tools(tm)
    messages = [SYSTEM_MSG]

    while True:
        user = input("‚úàÔ∏è  User: ")
        messages.append({"role": "user", "content": user})

        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=messages,
            tools=TOOLS,
            tool_choice="auto",
            stream=False,
        )

        msg = response.choices[0].message
        messages.append({"role": "assistant", "content": msg.content or "", "tool_calls": msg.tool_calls})

        # Handle tool calls
        if msg.tool_calls:
            for call in msg.tool_calls:
                fn_name = call.function.name
                args = json.loads(call.function.arguments or "{}")
                # Call the method directly
                result = CALLBACKS[fn_name](**args)

                # send tool message back
                messages.append(
                    {
                        "role": "tool",
                        "tool_call_id": call.id,
                        "name": fn_name,
                        "content": json.dumps(result, default=str)[:8000],
                    }
                )
            # continue the loop without printing assistant text yet
            continue

        print("ü§ñ", msg.content)

if __name__ == "__main__":
    # Example usage when run directly
    tm = ToolManager(
        project_path="xflrpy/projects/",
        project_name="test1.xfl",
        plane_name="baseline",
    )
    chat_loop(tm)
